---------------------------------------------------------------------------
Training stage 0
Sampled 12935 windows from 19071 images.
Done sampling windows (time=719s).
Computing lambdas... done (time=145s).
Extracting features... done (time=47s).
Sampled 25000 windows from 1024 images.
Done sampling windows (time=62s).
Extracting features... done (time=39s).
Training AdaBoost: nWeak= 64 nFtrs=5120 pos=25870 neg=25000
 i=  16 alpha=1.000 err=0.220 loss=1.52e-02
 i=  32 alpha=1.000 err=0.211 loss=6.71e-04
 i=  48 alpha=1.000 err=0.241 loss=2.98e-05
 i=  64 alpha=1.000 err=0.214 loss=1.29e-06
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=19.7s).
Done training stage 0 (time=1036s).
---------------------------------------------------------------------------
Training stage 1
Sampled 25000 windows from 1216 images.
Done sampling windows (time=227s).
Extracting features... done (time=42s).
Training AdaBoost: nWeak=256 nFtrs=5120 pos=25870 neg=50000
 i=  16 alpha=1.000 err=0.340 loss=2.31e-01
 i=  32 alpha=1.000 err=0.348 loss=1.00e-01
 i=  48 alpha=1.000 err=0.355 loss=4.52e-02
 i=  64 alpha=1.000 err=0.359 loss=2.01e-02
 i=  80 alpha=1.000 err=0.353 loss=8.94e-03
 i=  96 alpha=1.000 err=0.361 loss=4.04e-03
 i= 112 alpha=1.000 err=0.349 loss=1.86e-03
 i= 128 alpha=1.000 err=0.353 loss=8.09e-04
 i= 144 alpha=1.000 err=0.362 loss=3.62e-04
 i= 160 alpha=1.000 err=0.346 loss=1.58e-04
 i= 176 alpha=1.000 err=0.379 loss=6.94e-05
 i= 192 alpha=1.000 err=0.370 loss=3.16e-05
 i= 208 alpha=1.000 err=0.356 loss=1.40e-05
 i= 224 alpha=1.000 err=0.341 loss=6.04e-06
 i= 240 alpha=1.000 err=0.353 loss=2.60e-06
 i= 256 alpha=1.000 err=0.340 loss=1.13e-06
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=92.0s).
Done training stage 1 (time=365s).
---------------------------------------------------------------------------
Training stage 2
Sampled 25000 windows from 3712 images.
Done sampling windows (time=583s).
Extracting features... done (time=44s).
Training AdaBoost: nWeak=1024 nFtrs=5120 pos=25870 neg=50000
 i=  16 alpha=1.000 err=0.381 loss=3.56e-01
 i=  32 alpha=1.000 err=0.386 loss=2.05e-01
 i=  48 alpha=1.000 err=0.379 loss=1.17e-01
 i=  64 alpha=1.000 err=0.380 loss=6.76e-02
 i=  80 alpha=1.000 err=0.379 loss=3.91e-02
 i=  96 alpha=1.000 err=0.381 loss=2.28e-02
 i= 112 alpha=1.000 err=0.381 loss=1.31e-02
 i= 128 alpha=1.000 err=0.383 loss=7.59e-03
 i= 144 alpha=1.000 err=0.384 loss=4.38e-03
 i= 160 alpha=1.000 err=0.382 loss=2.49e-03
 i= 176 alpha=1.000 err=0.386 loss=1.40e-03
 i= 192 alpha=1.000 err=0.377 loss=7.97e-04
 i= 208 alpha=1.000 err=0.384 loss=4.53e-04
 i= 224 alpha=1.000 err=0.379 loss=2.59e-04
 i= 240 alpha=1.000 err=0.371 loss=1.44e-04
 i= 256 alpha=1.000 err=0.379 loss=8.41e-05
 i= 272 alpha=1.000 err=0.379 loss=4.92e-05
 i= 288 alpha=1.000 err=0.370 loss=2.72e-05
 i= 304 alpha=1.000 err=0.384 loss=1.57e-05
 i= 320 alpha=1.000 err=0.373 loss=8.71e-06
 i= 336 alpha=1.000 err=0.394 loss=5.00e-06
 i= 352 alpha=1.000 err=0.377 loss=2.79e-06
 i= 368 alpha=1.000 err=0.388 loss=1.61e-06
 i= 384 alpha=1.000 err=0.387 loss=9.23e-07
 i= 400 alpha=1.000 err=0.381 loss=5.27e-07
 i= 416 alpha=1.000 err=0.377 loss=2.96e-07
 i= 432 alpha=1.000 err=0.388 loss=1.64e-07
 i= 448 alpha=1.000 err=0.377 loss=9.33e-08
 i= 464 alpha=1.000 err=0.387 loss=5.21e-08
 i= 480 alpha=1.000 err=0.387 loss=2.88e-08
 i= 496 alpha=1.000 err=0.382 loss=1.60e-08
 i= 512 alpha=1.000 err=0.372 loss=8.84e-09
 i= 528 alpha=1.000 err=0.380 loss=4.96e-09
 i= 544 alpha=1.000 err=0.386 loss=2.81e-09
 i= 560 alpha=1.000 err=0.380 loss=1.59e-09
 i= 576 alpha=1.000 err=0.389 loss=9.01e-10
 i= 592 alpha=1.000 err=0.370 loss=5.06e-10
 i= 608 alpha=1.000 err=0.373 loss=2.82e-10
 i= 624 alpha=1.000 err=0.395 loss=1.60e-10
 i= 640 alpha=1.000 err=0.378 loss=8.71e-11
 i= 656 alpha=1.000 err=0.374 loss=4.80e-11
 i= 672 alpha=1.000 err=0.375 loss=2.70e-11
 i= 688 alpha=1.000 err=0.391 loss=1.51e-11
 i= 704 alpha=1.000 err=0.382 loss=8.48e-12
 i= 720 alpha=1.000 err=0.380 loss=4.74e-12
 i= 736 alpha=1.000 err=0.380 loss=2.56e-12
 i= 752 alpha=1.000 err=0.380 loss=1.44e-12
 i= 768 alpha=1.000 err=0.371 loss=7.88e-13
 i= 784 alpha=1.000 err=0.376 loss=4.32e-13
 i= 800 alpha=1.000 err=0.383 loss=2.46e-13
 i= 816 alpha=1.000 err=0.384 loss=1.39e-13
 i= 832 alpha=1.000 err=0.380 loss=7.66e-14
 i= 848 alpha=1.000 err=0.376 loss=4.19e-14
 i= 864 alpha=1.000 err=0.382 loss=2.38e-14
 i= 880 alpha=1.000 err=0.371 loss=1.32e-14
 i= 896 alpha=1.000 err=0.379 loss=7.46e-15
 i= 912 alpha=1.000 err=0.383 loss=4.21e-15
 i= 928 alpha=1.000 err=0.384 loss=2.34e-15
 i= 944 alpha=1.000 err=0.373 loss=1.32e-15
 i= 960 alpha=1.000 err=0.383 loss=7.35e-16
 i= 976 alpha=1.000 err=0.376 loss=4.22e-16
 i= 992 alpha=1.000 err=0.379 loss=2.33e-16
 i=1008 alpha=1.000 err=0.379 loss=1.29e-16
 i=1024 alpha=1.000 err=0.381 loss=7.06e-17
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=358.7s).
Done training stage 2 (time=990s).
---------------------------------------------------------------------------
Training stage 3
Sampled 10094 windows from 19071 images.
Done sampling windows (time=2782s).
Extracting features... done (time=14s).
Training AdaBoost: nWeak=4096 nFtrs=5120 pos=25870 neg=50000
 i=  16 alpha=1.000 err=0.390 loss=4.31e-01
 i=  32 alpha=1.000 err=0.404 loss=2.81e-01
 i=  48 alpha=1.000 err=0.398 loss=1.83e-01
 i=  64 alpha=1.000 err=0.404 loss=1.20e-01
 i=  80 alpha=1.000 err=0.397 loss=7.93e-02
 i=  96 alpha=1.000 err=0.399 loss=5.20e-02
 i= 112 alpha=1.000 err=0.391 loss=3.40e-02
 i= 128 alpha=1.000 err=0.403 loss=2.19e-02
 i= 144 alpha=1.000 err=0.401 loss=1.44e-02
 i= 160 alpha=1.000 err=0.394 loss=9.29e-03
 i= 176 alpha=1.000 err=0.393 loss=5.95e-03
 i= 192 alpha=1.000 err=0.396 loss=3.87e-03
 i= 208 alpha=1.000 err=0.385 loss=2.47e-03
 i= 224 alpha=1.000 err=0.395 loss=1.61e-03
 i= 240 alpha=1.000 err=0.398 loss=1.03e-03
 i= 256 alpha=1.000 err=0.388 loss=6.61e-04
 i= 272 alpha=1.000 err=0.390 loss=4.19e-04
 i= 288 alpha=1.000 err=0.399 loss=2.68e-04
 i= 304 alpha=1.000 err=0.389 loss=1.72e-04
 i= 320 alpha=1.000 err=0.391 loss=1.10e-04
 i= 336 alpha=1.000 err=0.382 loss=7.09e-05
 i= 352 alpha=1.000 err=0.390 loss=4.53e-05
 i= 368 alpha=1.000 err=0.396 loss=2.88e-05
 i= 384 alpha=1.000 err=0.398 loss=1.86e-05
 i= 400 alpha=1.000 err=0.394 loss=1.17e-05
 i= 416 alpha=1.000 err=0.392 loss=7.53e-06
 i= 432 alpha=1.000 err=0.393 loss=4.75e-06
 i= 448 alpha=1.000 err=0.386 loss=3.02e-06
 i= 464 alpha=1.000 err=0.390 loss=1.92e-06
 i= 480 alpha=1.000 err=0.406 loss=1.22e-06
 i= 496 alpha=1.000 err=0.397 loss=7.68e-07
 i= 512 alpha=1.000 err=0.404 loss=4.86e-07
 i= 528 alpha=1.000 err=0.397 loss=3.07e-07
 i= 544 alpha=1.000 err=0.401 loss=1.97e-07
 i= 560 alpha=1.000 err=0.389 loss=1.24e-07
 i= 576 alpha=1.000 err=0.391 loss=7.81e-08
 i= 592 alpha=1.000 err=0.400 loss=5.00e-08
 i= 608 alpha=1.000 err=0.389 loss=3.17e-08
 i= 624 alpha=1.000 err=0.390 loss=1.96e-08
 i= 640 alpha=1.000 err=0.400 loss=1.24e-08
 i= 656 alpha=1.000 err=0.397 loss=7.85e-09
 i= 672 alpha=1.000 err=0.391 loss=5.00e-09
 i= 688 alpha=1.000 err=0.388 loss=3.18e-09
 i= 704 alpha=1.000 err=0.401 loss=2.01e-09
 i= 720 alpha=1.000 err=0.400 loss=1.30e-09
 i= 736 alpha=1.000 err=0.398 loss=8.23e-10
 i= 752 alpha=1.000 err=0.398 loss=5.23e-10
 i= 768 alpha=1.000 err=0.394 loss=3.34e-10
 i= 784 alpha=1.000 err=0.398 loss=2.16e-10
 i= 800 alpha=1.000 err=0.390 loss=1.37e-10
 i= 816 alpha=1.000 err=0.402 loss=8.71e-11
 i= 832 alpha=1.000 err=0.388 loss=5.53e-11
 i= 848 alpha=1.000 err=0.397 loss=3.46e-11
 i= 864 alpha=1.000 err=0.410 loss=2.18e-11
 i= 880 alpha=1.000 err=0.400 loss=1.39e-11
 i= 896 alpha=1.000 err=0.401 loss=8.80e-12
 i= 912 alpha=1.000 err=0.399 loss=5.56e-12
 i= 928 alpha=1.000 err=0.402 loss=3.50e-12
 i= 944 alpha=1.000 err=0.393 loss=2.21e-12
 i= 960 alpha=1.000 err=0.395 loss=1.41e-12
 i= 976 alpha=1.000 err=0.398 loss=9.00e-13
 i= 992 alpha=1.000 err=0.390 loss=5.66e-13
 i=1008 alpha=1.000 err=0.388 loss=3.56e-13
 i=1024 alpha=1.000 err=0.397 loss=2.30e-13
 i=1040 alpha=1.000 err=0.394 loss=1.46e-13
 i=1056 alpha=1.000 err=0.400 loss=9.13e-14
 i=1072 alpha=1.000 err=0.398 loss=5.72e-14
 i=1088 alpha=1.000 err=0.383 loss=3.64e-14
 i=1104 alpha=1.000 err=0.394 loss=2.33e-14
 i=1120 alpha=1.000 err=0.387 loss=1.46e-14
 i=1136 alpha=1.000 err=0.385 loss=9.17e-15
 i=1152 alpha=1.000 err=0.394 loss=5.87e-15
 i=1168 alpha=1.000 err=0.396 loss=3.71e-15
 i=1184 alpha=1.000 err=0.389 loss=2.34e-15
 i=1200 alpha=1.000 err=0.404 loss=1.48e-15
 i=1216 alpha=1.000 err=0.392 loss=9.35e-16
 i=1232 alpha=1.000 err=0.392 loss=5.90e-16
 i=1248 alpha=1.000 err=0.398 loss=3.75e-16
 i=1264 alpha=1.000 err=0.402 loss=2.40e-16
 i=1280 alpha=1.000 err=0.393 loss=1.53e-16
 i=1296 alpha=1.000 err=0.391 loss=9.61e-17
 i=1312 alpha=1.000 err=0.391 loss=6.15e-17
 i=1328 alpha=1.000 err=0.403 loss=3.93e-17
 i=1344 alpha=1.000 err=0.390 loss=2.44e-17
 i=1360 alpha=1.000 err=0.376 loss=1.52e-17
 i=1376 alpha=1.000 err=0.390 loss=9.44e-18
 i=1392 alpha=1.000 err=0.390 loss=5.96e-18
 i=1408 alpha=1.000 err=0.384 loss=3.76e-18
 i=1424 alpha=1.000 err=0.395 loss=2.37e-18
 i=1440 alpha=1.000 err=0.392 loss=1.48e-18
 i=1456 alpha=1.000 err=0.400 loss=9.48e-19
 i=1472 alpha=1.000 err=0.393 loss=6.03e-19
 i=1488 alpha=1.000 err=0.400 loss=3.83e-19
 i=1504 alpha=1.000 err=0.405 loss=2.46e-19
 i=1520 alpha=1.000 err=0.391 loss=1.55e-19
 i=1536 alpha=1.000 err=0.396 loss=9.89e-20
 i=1552 alpha=1.000 err=0.391 loss=6.33e-20
 i=1568 alpha=1.000 err=0.386 loss=4.03e-20
 i=1584 alpha=1.000 err=0.397 loss=2.55e-20
 i=1600 alpha=1.000 err=0.395 loss=1.59e-20
 i=1616 alpha=1.000 err=0.393 loss=9.93e-21
 i=1632 alpha=1.000 err=0.401 loss=6.30e-21
 i=1648 alpha=1.000 err=0.392 loss=3.97e-21
 i=1664 alpha=1.000 err=0.401 loss=2.53e-21
 i=1680 alpha=1.000 err=0.388 loss=1.58e-21
 i=1696 alpha=1.000 err=0.392 loss=9.97e-22
 i=1712 alpha=1.000 err=0.380 loss=6.25e-22
 i=1728 alpha=1.000 err=0.383 loss=3.88e-22
 i=1744 alpha=1.000 err=0.398 loss=2.46e-22
 i=1760 alpha=1.000 err=0.391 loss=1.57e-22
 i=1776 alpha=1.000 err=0.390 loss=9.84e-23
 i=1792 alpha=1.000 err=0.382 loss=6.21e-23
 i=1808 alpha=1.000 err=0.400 loss=3.94e-23
 i=1824 alpha=1.000 err=0.393 loss=2.52e-23
 i=1840 alpha=1.000 err=0.401 loss=1.62e-23
 i=1856 alpha=1.000 err=0.380 loss=1.02e-23
 i=1872 alpha=1.000 err=0.396 loss=6.42e-24
 i=1888 alpha=1.000 err=0.399 loss=4.09e-24
 i=1904 alpha=1.000 err=0.397 loss=2.57e-24
 i=1920 alpha=1.000 err=0.388 loss=1.60e-24
 i=1936 alpha=1.000 err=0.384 loss=1.02e-24
 i=1952 alpha=1.000 err=0.396 loss=6.46e-25
 i=1968 alpha=1.000 err=0.407 loss=4.06e-25
 i=1984 alpha=1.000 err=0.391 loss=2.57e-25
 i=2000 alpha=1.000 err=0.407 loss=1.66e-25
 i=2016 alpha=1.000 err=0.381 loss=1.07e-25
 i=2032 alpha=1.000 err=0.397 loss=6.73e-26
 i=2048 alpha=1.000 err=0.388 loss=4.27e-26
 i=2064 alpha=1.000 err=0.398 loss=2.66e-26
 i=2080 alpha=1.000 err=0.390 loss=1.67e-26
 i=2096 alpha=1.000 err=0.384 loss=1.06e-26
 i=2112 alpha=1.000 err=0.396 loss=6.71e-27
 i=2128 alpha=1.000 err=0.393 loss=4.18e-27
 i=2144 alpha=1.000 err=0.390 loss=2.60e-27
 i=2160 alpha=1.000 err=0.392 loss=1.63e-27
 i=2176 alpha=1.000 err=0.396 loss=1.03e-27
 i=2192 alpha=1.000 err=0.395 loss=6.55e-28
 i=2208 alpha=1.000 err=0.389 loss=4.16e-28
 i=2224 alpha=1.000 err=0.395 loss=2.63e-28
 i=2240 alpha=1.000 err=0.391 loss=1.66e-28
 i=2256 alpha=1.000 err=0.387 loss=1.04e-28
 i=2272 alpha=1.000 err=0.397 loss=6.56e-29
 i=2288 alpha=1.000 err=0.391 loss=4.18e-29
 i=2304 alpha=1.000 err=0.391 loss=2.63e-29
 i=2320 alpha=1.000 err=0.398 loss=1.65e-29
 i=2336 alpha=1.000 err=0.401 loss=1.04e-29
 i=2352 alpha=1.000 err=0.387 loss=6.60e-30
 i=2368 alpha=1.000 err=0.401 loss=4.15e-30
 i=2384 alpha=1.000 err=0.392 loss=2.63e-30
 i=2400 alpha=1.000 err=0.392 loss=1.67e-30
 i=2416 alpha=1.000 err=0.394 loss=1.04e-30
 i=2432 alpha=1.000 err=0.377 loss=6.60e-31
 i=2448 alpha=1.000 err=0.385 loss=4.07e-31
 i=2464 alpha=1.000 err=0.399 loss=2.59e-31
 i=2480 alpha=1.000 err=0.395 loss=1.63e-31
 i=2496 alpha=1.000 err=0.393 loss=1.02e-31
 i=2512 alpha=1.000 err=0.385 loss=6.36e-32
 i=2528 alpha=1.000 err=0.406 loss=4.05e-32
 i=2544 alpha=1.000 err=0.394 loss=2.55e-32
 i=2560 alpha=1.000 err=0.392 loss=1.61e-32
 i=2576 alpha=1.000 err=0.413 loss=1.02e-32
 i=2592 alpha=1.000 err=0.396 loss=6.52e-33
 i=2608 alpha=1.000 err=0.403 loss=4.13e-33
 i=2624 alpha=1.000 err=0.387 loss=2.62e-33
 i=2640 alpha=1.000 err=0.394 loss=1.66e-33
 i=2656 alpha=1.000 err=0.407 loss=1.04e-33
 i=2672 alpha=1.000 err=0.394 loss=6.67e-34
 i=2688 alpha=1.000 err=0.393 loss=4.25e-34
 i=2704 alpha=1.000 err=0.396 loss=2.68e-34
 i=2720 alpha=1.000 err=0.399 loss=1.69e-34
 i=2736 alpha=1.000 err=0.399 loss=1.06e-34
 i=2752 alpha=1.000 err=0.390 loss=6.81e-35
 i=2768 alpha=1.000 err=0.390 loss=4.26e-35
 i=2784 alpha=1.000 err=0.401 loss=2.70e-35
 i=2800 alpha=1.000 err=0.401 loss=1.69e-35
 i=2816 alpha=1.000 err=0.400 loss=1.08e-35
 i=2832 alpha=1.000 err=0.394 loss=6.95e-36
 i=2848 alpha=1.000 err=0.400 loss=4.41e-36
 i=2864 alpha=1.000 err=0.399 loss=2.79e-36
 i=2880 alpha=1.000 err=0.388 loss=1.76e-36
 i=2896 alpha=1.000 err=0.391 loss=1.13e-36
 i=2912 alpha=1.000 err=0.392 loss=7.23e-37
 i=2928 alpha=1.000 err=0.397 loss=4.49e-37
 i=2944 alpha=1.000 err=0.397 loss=2.80e-37
 i=2960 alpha=1.000 err=0.385 loss=1.73e-37
 i=2976 alpha=1.000 err=0.389 loss=1.11e-37
 i=2992 alpha=1.000 err=0.396 loss=7.13e-38
 i=3008 alpha=1.000 err=0.393 loss=4.55e-38
 i=3024 alpha=1.000 err=0.399 loss=2.84e-38
 i=3040 alpha=1.000 err=0.392 loss=1.82e-38
 i=3056 alpha=1.000 err=0.404 loss=1.15e-38
 i=3072 alpha=1.000 err=0.388 loss=7.07e-39
 i=3088 alpha=1.000 err=0.388 loss=4.49e-39
 i=3104 alpha=1.000 err=0.389 loss=2.86e-39
 i=3120 alpha=1.000 err=0.381 loss=1.81e-39
 i=3136 alpha=1.000 err=0.400 loss=1.16e-39
 i=3152 alpha=1.000 err=0.396 loss=7.43e-40
 i=3168 alpha=1.000 err=0.401 loss=4.65e-40
 i=3184 alpha=1.000 err=0.397 loss=2.95e-40
 i=3200 alpha=1.000 err=0.388 loss=1.89e-40
 i=3216 alpha=1.000 err=0.397 loss=1.19e-40
 stopping early
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=1104.0s).
Done training stage 3 (time=3903s).
---------------------------------------------------------------------------
Done training (time=6295s).
