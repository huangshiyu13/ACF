---------------------------------------------------------------------------
Training stage 0
Sampled 9014 windows from 9071 images.
Done sampling windows (time=374s).
Computing lambdas... done (time=32s).
Extracting features... done (time=5s).
Sampled 5000 windows from 256 images.
Done sampling windows (time=3s).
Extracting features... done (time=2s).
Training AdaBoost: nWeak= 64 nFtrs=5120 pos=18028 neg=5000
 i=  16 alpha=1.000 err=0.067 loss=3.14e-06
 i=  32 alpha=1.000 err=0.062 loss=2.21e-12
 i=  48 alpha=1.000 err=0.044 loss=6.29e-19
 i=  64 alpha=1.000 err=0.053 loss=2.18e-25
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=3.0s).
Done training stage 0 (time=420s).
---------------------------------------------------------------------------
Training stage 1
Sampled 5000 windows from 256 images.
Done sampling windows (time=18s).
Extracting features... done (time=1s).
Training AdaBoost: nWeak=256 nFtrs=5120 pos=18028 neg=10000
 i=  16 alpha=1.000 err=0.285 loss=6.79e-02
 i=  32 alpha=1.000 err=0.292 loss=7.62e-03
 i=  48 alpha=1.000 err=0.269 loss=8.14e-04
 i=  64 alpha=1.000 err=0.271 loss=7.96e-05
 i=  80 alpha=1.000 err=0.282 loss=7.94e-06
 i=  96 alpha=1.000 err=0.260 loss=7.03e-07
 i= 112 alpha=1.000 err=0.283 loss=7.00e-08
 i= 128 alpha=1.000 err=0.271 loss=6.16e-09
 i= 144 alpha=1.000 err=0.242 loss=5.01e-10
 i= 160 alpha=1.000 err=0.260 loss=4.36e-11
 i= 176 alpha=1.000 err=0.281 loss=4.02e-12
 i= 192 alpha=1.000 err=0.277 loss=3.76e-13
 i= 208 alpha=1.000 err=0.274 loss=3.47e-14
 i= 224 alpha=1.000 err=0.247 loss=2.85e-15
 i= 240 alpha=1.000 err=0.261 loss=2.16e-16
 i= 256 alpha=1.000 err=0.263 loss=1.68e-17
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=13.9s).
Done training stage 1 (time=33s).
---------------------------------------------------------------------------
Training stage 2
Sampled 5000 windows from 1408 images.
Done sampling windows (time=79s).
Extracting features... done (time=1s).
Training AdaBoost: nWeak=1024 nFtrs=5120 pos=18028 neg=10000
 i=  16 alpha=1.000 err=0.373 loss=3.42e-01
 i=  32 alpha=1.000 err=0.371 loss=1.73e-01
 i=  48 alpha=1.000 err=0.373 loss=8.39e-02
 i=  64 alpha=1.000 err=0.352 loss=3.92e-02
 i=  80 alpha=1.000 err=0.352 loss=1.82e-02
 i=  96 alpha=1.000 err=0.367 loss=8.50e-03
 i= 112 alpha=1.000 err=0.373 loss=4.01e-03
 i= 128 alpha=1.000 err=0.359 loss=1.83e-03
 i= 144 alpha=1.000 err=0.363 loss=8.45e-04
 i= 160 alpha=1.000 err=0.355 loss=3.93e-04
 i= 176 alpha=1.000 err=0.368 loss=1.85e-04
 i= 192 alpha=1.000 err=0.376 loss=8.72e-05
 i= 208 alpha=1.000 err=0.379 loss=3.99e-05
 i= 224 alpha=1.000 err=0.360 loss=1.85e-05
 i= 240 alpha=1.000 err=0.367 loss=8.39e-06
 i= 256 alpha=1.000 err=0.365 loss=3.87e-06
 i= 272 alpha=1.000 err=0.374 loss=1.83e-06
 i= 288 alpha=1.000 err=0.363 loss=8.44e-07
 i= 304 alpha=1.000 err=0.358 loss=4.00e-07
 i= 320 alpha=1.000 err=0.364 loss=1.98e-07
 i= 336 alpha=1.000 err=0.368 loss=9.15e-08
 i= 352 alpha=1.000 err=0.349 loss=4.18e-08
 i= 368 alpha=1.000 err=0.350 loss=2.00e-08
 i= 384 alpha=1.000 err=0.366 loss=9.30e-09
 i= 400 alpha=1.000 err=0.373 loss=4.25e-09
 i= 416 alpha=1.000 err=0.357 loss=1.89e-09
 i= 432 alpha=1.000 err=0.361 loss=8.79e-10
 i= 448 alpha=1.000 err=0.361 loss=4.18e-10
 i= 464 alpha=1.000 err=0.365 loss=1.91e-10
 i= 480 alpha=1.000 err=0.352 loss=8.75e-11
 i= 496 alpha=1.000 err=0.352 loss=3.93e-11
 i= 512 alpha=1.000 err=0.358 loss=1.81e-11
 i= 528 alpha=1.000 err=0.350 loss=8.18e-12
 i= 544 alpha=1.000 err=0.351 loss=3.78e-12
 i= 560 alpha=1.000 err=0.372 loss=1.71e-12
 i= 576 alpha=1.000 err=0.363 loss=7.94e-13
 i= 592 alpha=1.000 err=0.367 loss=3.56e-13
 i= 608 alpha=1.000 err=0.352 loss=1.62e-13
 i= 624 alpha=1.000 err=0.359 loss=7.15e-14
 i= 640 alpha=1.000 err=0.354 loss=3.17e-14
 i= 656 alpha=1.000 err=0.356 loss=1.47e-14
 i= 672 alpha=1.000 err=0.360 loss=6.73e-15
 i= 688 alpha=1.000 err=0.354 loss=3.20e-15
 i= 704 alpha=1.000 err=0.354 loss=1.46e-15
 i= 720 alpha=1.000 err=0.362 loss=6.65e-16
 i= 736 alpha=1.000 err=0.364 loss=3.14e-16
 i= 752 alpha=1.000 err=0.381 loss=1.45e-16
 i= 768 alpha=1.000 err=0.371 loss=6.86e-17
 i= 784 alpha=1.000 err=0.372 loss=3.12e-17
 i= 800 alpha=1.000 err=0.383 loss=1.45e-17
 i= 816 alpha=1.000 err=0.378 loss=6.60e-18
 i= 832 alpha=1.000 err=0.362 loss=3.05e-18
 i= 848 alpha=1.000 err=0.358 loss=1.40e-18
 i= 864 alpha=1.000 err=0.360 loss=6.28e-19
 i= 880 alpha=1.000 err=0.367 loss=2.91e-19
 i= 896 alpha=1.000 err=0.372 loss=1.29e-19
 i= 912 alpha=1.000 err=0.364 loss=5.78e-20
 i= 928 alpha=1.000 err=0.363 loss=2.59e-20
 i= 944 alpha=1.000 err=0.355 loss=1.16e-20
 i= 960 alpha=1.000 err=0.361 loss=5.32e-21
 i= 976 alpha=1.000 err=0.364 loss=2.41e-21
 i= 992 alpha=1.000 err=0.359 loss=1.10e-21
 i=1008 alpha=1.000 err=0.359 loss=5.05e-22
 i=1024 alpha=1.000 err=0.356 loss=2.27e-22
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=57.6s).
Done training stage 2 (time=138s).
---------------------------------------------------------------------------
Training stage 3
Sampled 5000 windows from 3072 images.
Done sampling windows (time=170s).
Extracting features... done (time=2s).
Training AdaBoost: nWeak=4096 nFtrs=5120 pos=18028 neg=10000
 i=  16 alpha=1.000 err=0.386 loss=5.08e-01
 i=  32 alpha=1.000 err=0.383 loss=3.21e-01
 i=  48 alpha=1.000 err=0.386 loss=2.01e-01
 i=  64 alpha=1.000 err=0.388 loss=1.25e-01
 i=  80 alpha=1.000 err=0.386 loss=7.69e-02
 i=  96 alpha=1.000 err=0.391 loss=4.80e-02
 i= 112 alpha=1.000 err=0.385 loss=2.98e-02
 i= 128 alpha=1.000 err=0.402 loss=1.86e-02
 i= 144 alpha=1.000 err=0.390 loss=1.16e-02
 i= 160 alpha=1.000 err=0.393 loss=7.04e-03
 i= 176 alpha=1.000 err=0.380 loss=4.36e-03
 i= 192 alpha=1.000 err=0.393 loss=2.69e-03
 i= 208 alpha=1.000 err=0.390 loss=1.65e-03
 i= 224 alpha=1.000 err=0.382 loss=9.89e-04
 i= 240 alpha=1.000 err=0.396 loss=5.96e-04
 i= 256 alpha=1.000 err=0.396 loss=3.70e-04
 i= 272 alpha=1.000 err=0.392 loss=2.28e-04
 i= 288 alpha=1.000 err=0.398 loss=1.40e-04
 i= 304 alpha=1.000 err=0.400 loss=8.61e-05
 i= 320 alpha=1.000 err=0.389 loss=5.19e-05
 i= 336 alpha=1.000 err=0.386 loss=3.12e-05
 i= 352 alpha=1.000 err=0.391 loss=1.92e-05
 i= 368 alpha=1.000 err=0.389 loss=1.15e-05
 i= 384 alpha=1.000 err=0.397 loss=7.15e-06
 i= 400 alpha=1.000 err=0.395 loss=4.27e-06
 i= 416 alpha=1.000 err=0.394 loss=2.61e-06
 i= 432 alpha=1.000 err=0.382 loss=1.58e-06
 i= 448 alpha=1.000 err=0.390 loss=9.55e-07
 i= 464 alpha=1.000 err=0.391 loss=5.78e-07
 i= 480 alpha=1.000 err=0.390 loss=3.46e-07
 i= 496 alpha=1.000 err=0.394 loss=2.08e-07
 i= 512 alpha=1.000 err=0.387 loss=1.25e-07
 i= 528 alpha=1.000 err=0.388 loss=7.61e-08
 i= 544 alpha=1.000 err=0.385 loss=4.56e-08
 i= 560 alpha=1.000 err=0.404 loss=2.82e-08
 i= 576 alpha=1.000 err=0.389 loss=1.72e-08
 i= 592 alpha=1.000 err=0.387 loss=1.04e-08
 i= 608 alpha=1.000 err=0.378 loss=6.23e-09
 i= 624 alpha=1.000 err=0.376 loss=3.76e-09
 i= 640 alpha=1.000 err=0.399 loss=2.26e-09
 i= 656 alpha=1.000 err=0.393 loss=1.32e-09
 i= 672 alpha=1.000 err=0.398 loss=8.03e-10
 i= 688 alpha=1.000 err=0.401 loss=4.86e-10
 i= 704 alpha=1.000 err=0.388 loss=2.93e-10
 i= 720 alpha=1.000 err=0.385 loss=1.77e-10
 i= 736 alpha=1.000 err=0.388 loss=1.04e-10
 i= 752 alpha=1.000 err=0.394 loss=6.24e-11
 i= 768 alpha=1.000 err=0.378 loss=3.76e-11
 i= 784 alpha=1.000 err=0.394 loss=2.29e-11
 i= 800 alpha=1.000 err=0.380 loss=1.37e-11
 i= 816 alpha=1.000 err=0.399 loss=8.25e-12
 i= 832 alpha=1.000 err=0.386 loss=4.88e-12
 i= 848 alpha=1.000 err=0.382 loss=2.91e-12
 i= 864 alpha=1.000 err=0.396 loss=1.78e-12
 i= 880 alpha=1.000 err=0.397 loss=1.08e-12
 i= 896 alpha=1.000 err=0.399 loss=6.60e-13
 i= 912 alpha=1.000 err=0.392 loss=3.88e-13
 i= 928 alpha=1.000 err=0.390 loss=2.37e-13
 i= 944 alpha=1.000 err=0.383 loss=1.44e-13
 i= 960 alpha=1.000 err=0.401 loss=8.69e-14
 i= 976 alpha=1.000 err=0.394 loss=5.22e-14
 i= 992 alpha=1.000 err=0.392 loss=3.20e-14
 i=1008 alpha=1.000 err=0.397 loss=1.93e-14
 i=1024 alpha=1.000 err=0.389 loss=1.15e-14
 i=1040 alpha=1.000 err=0.384 loss=6.90e-15
 i=1056 alpha=1.000 err=0.392 loss=4.27e-15
 i=1072 alpha=1.000 err=0.383 loss=2.61e-15
 i=1088 alpha=1.000 err=0.378 loss=1.58e-15
 i=1104 alpha=1.000 err=0.393 loss=9.60e-16
 i=1120 alpha=1.000 err=0.393 loss=5.72e-16
 i=1136 alpha=1.000 err=0.400 loss=3.49e-16
 i=1152 alpha=1.000 err=0.386 loss=2.08e-16
 i=1168 alpha=1.000 err=0.394 loss=1.26e-16
 i=1184 alpha=1.000 err=0.386 loss=7.67e-17
 i=1200 alpha=1.000 err=0.383 loss=4.56e-17
 i=1216 alpha=1.000 err=0.375 loss=2.74e-17
 i=1232 alpha=1.000 err=0.388 loss=1.62e-17
 i=1248 alpha=1.000 err=0.380 loss=9.66e-18
 i=1264 alpha=1.000 err=0.397 loss=5.77e-18
 i=1280 alpha=1.000 err=0.396 loss=3.52e-18
 i=1296 alpha=1.000 err=0.386 loss=2.11e-18
 i=1312 alpha=1.000 err=0.397 loss=1.28e-18
 i=1328 alpha=1.000 err=0.395 loss=7.66e-19
 i=1344 alpha=1.000 err=0.388 loss=4.63e-19
 i=1360 alpha=1.000 err=0.389 loss=2.80e-19
 i=1376 alpha=1.000 err=0.389 loss=1.69e-19
 i=1392 alpha=1.000 err=0.388 loss=1.00e-19
 i=1408 alpha=1.000 err=0.390 loss=5.95e-20
 i=1424 alpha=1.000 err=0.395 loss=3.50e-20
 i=1440 alpha=1.000 err=0.391 loss=2.12e-20
 i=1456 alpha=1.000 err=0.379 loss=1.27e-20
 i=1472 alpha=1.000 err=0.394 loss=7.67e-21
 i=1488 alpha=1.000 err=0.393 loss=4.61e-21
 i=1504 alpha=1.000 err=0.387 loss=2.77e-21
 i=1520 alpha=1.000 err=0.382 loss=1.63e-21
 i=1536 alpha=1.000 err=0.385 loss=9.94e-22
 i=1552 alpha=1.000 err=0.396 loss=5.93e-22
 i=1568 alpha=1.000 err=0.387 loss=3.56e-22
 i=1584 alpha=1.000 err=0.386 loss=2.15e-22
 i=1600 alpha=1.000 err=0.390 loss=1.29e-22
 i=1616 alpha=1.000 err=0.384 loss=7.82e-23
 i=1632 alpha=1.000 err=0.392 loss=4.62e-23
 i=1648 alpha=1.000 err=0.393 loss=2.78e-23
 i=1664 alpha=1.000 err=0.382 loss=1.62e-23
 i=1680 alpha=1.000 err=0.385 loss=9.50e-24
 i=1696 alpha=1.000 err=0.396 loss=5.73e-24
 i=1712 alpha=1.000 err=0.378 loss=3.47e-24
 i=1728 alpha=1.000 err=0.397 loss=2.06e-24
 i=1744 alpha=1.000 err=0.393 loss=1.24e-24
 i=1760 alpha=1.000 err=0.390 loss=7.52e-25
 i=1776 alpha=1.000 err=0.402 loss=4.49e-25
 i=1792 alpha=1.000 err=0.389 loss=2.70e-25
 i=1808 alpha=1.000 err=0.397 loss=1.63e-25
 i=1824 alpha=1.000 err=0.397 loss=9.88e-26
 i=1840 alpha=1.000 err=0.378 loss=5.89e-26
 i=1856 alpha=1.000 err=0.386 loss=3.45e-26
 i=1872 alpha=1.000 err=0.382 loss=2.09e-26
 i=1888 alpha=1.000 err=0.385 loss=1.27e-26
 i=1904 alpha=1.000 err=0.390 loss=7.60e-27
 i=1920 alpha=1.000 err=0.390 loss=4.60e-27
 i=1936 alpha=1.000 err=0.395 loss=2.71e-27
 i=1952 alpha=1.000 err=0.391 loss=1.64e-27
 i=1968 alpha=1.000 err=0.383 loss=9.88e-28
 i=1984 alpha=1.000 err=0.401 loss=6.03e-28
 i=2000 alpha=1.000 err=0.384 loss=3.63e-28
 i=2016 alpha=1.000 err=0.385 loss=2.18e-28
 i=2032 alpha=1.000 err=0.402 loss=1.32e-28
 i=2048 alpha=1.000 err=0.393 loss=8.01e-29
 i=2064 alpha=1.000 err=0.397 loss=4.89e-29
 i=2080 alpha=1.000 err=0.390 loss=2.92e-29
 i=2096 alpha=1.000 err=0.389 loss=1.78e-29
 i=2112 alpha=1.000 err=0.387 loss=1.06e-29
 i=2128 alpha=1.000 err=0.392 loss=6.44e-30
 i=2144 alpha=1.000 err=0.391 loss=3.85e-30
 i=2160 alpha=1.000 err=0.393 loss=2.30e-30
 i=2176 alpha=1.000 err=0.397 loss=1.40e-30
 i=2192 alpha=1.000 err=0.380 loss=8.30e-31
 i=2208 alpha=1.000 err=0.389 loss=4.88e-31
 i=2224 alpha=1.000 err=0.397 loss=2.95e-31
 i=2240 alpha=1.000 err=0.393 loss=1.79e-31
 i=2256 alpha=1.000 err=0.392 loss=1.07e-31
 i=2272 alpha=1.000 err=0.389 loss=6.39e-32
 i=2288 alpha=1.000 err=0.396 loss=3.81e-32
 i=2304 alpha=1.000 err=0.378 loss=2.31e-32
 i=2320 alpha=1.000 err=0.379 loss=1.37e-32
 i=2336 alpha=1.000 err=0.388 loss=8.25e-33
 i=2352 alpha=1.000 err=0.391 loss=4.94e-33
 i=2368 alpha=1.000 err=0.389 loss=2.95e-33
 i=2384 alpha=1.000 err=0.394 loss=1.76e-33
 i=2400 alpha=1.000 err=0.388 loss=1.05e-33
 i=2416 alpha=1.000 err=0.388 loss=6.25e-34
 i=2432 alpha=1.000 err=0.385 loss=3.73e-34
 i=2448 alpha=1.000 err=0.381 loss=2.21e-34
 i=2464 alpha=1.000 err=0.384 loss=1.29e-34
 i=2480 alpha=1.000 err=0.388 loss=7.79e-35
 i=2496 alpha=1.000 err=0.386 loss=4.57e-35
 i=2512 alpha=1.000 err=0.398 loss=2.75e-35
 i=2528 alpha=1.000 err=0.381 loss=1.64e-35
 i=2544 alpha=1.000 err=0.395 loss=9.88e-36
 i=2560 alpha=1.000 err=0.384 loss=5.96e-36
 i=2576 alpha=1.000 err=0.390 loss=3.66e-36
 i=2592 alpha=1.000 err=0.391 loss=2.15e-36
 i=2608 alpha=1.000 err=0.392 loss=1.28e-36
 i=2624 alpha=1.000 err=0.386 loss=7.59e-37
 i=2640 alpha=1.000 err=0.397 loss=4.50e-37
 i=2656 alpha=1.000 err=0.395 loss=2.71e-37
 i=2672 alpha=1.000 err=0.396 loss=1.66e-37
 i=2688 alpha=1.000 err=0.391 loss=1.01e-37
 i=2704 alpha=1.000 err=0.380 loss=6.13e-38
 i=2720 alpha=1.000 err=0.390 loss=3.75e-38
 i=2736 alpha=1.000 err=0.392 loss=2.30e-38
 i=2752 alpha=1.000 err=0.385 loss=1.38e-38
 i=2768 alpha=1.000 err=0.382 loss=8.25e-39
 i=2784 alpha=1.000 err=0.383 loss=4.98e-39
 i=2800 alpha=1.000 err=0.386 loss=2.89e-39
 i=2816 alpha=1.000 err=0.378 loss=1.73e-39
 i=2832 alpha=1.000 err=0.386 loss=1.07e-39
 i=2848 alpha=1.000 err=0.383 loss=6.39e-40
 i=2864 alpha=1.000 err=0.382 loss=3.81e-40
 i=2880 alpha=1.000 err=0.389 loss=2.24e-40
 i=2896 alpha=1.000 err=0.387 loss=1.34e-40
 stopping early
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=165.0s).
Done training stage 3 (time=337s).
---------------------------------------------------------------------------
Done training (time=928s).
