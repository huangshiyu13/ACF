---------------------------------------------------------------------------
Training stage 0
Sampled 21263 windows from 41148 images.
Done sampling windows (time=977s).
Computing lambdas... done (time=78s).
Extracting features... done (time=12s).
Sampled 25000 windows from 1024 images.
Done sampling windows (time=31s).
Extracting features... done (time=7s).
Training AdaBoost: nWeak= 64 nFtrs=5120 pos=42526 neg=25000
 i=  16 alpha=1.000 err=0.254 loss=2.53e-02
 i=  32 alpha=1.000 err=0.252 loss=1.92e-03
 i=  48 alpha=1.000 err=0.242 loss=1.43e-04
 i=  64 alpha=1.000 err=0.250 loss=1.12e-05
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=8.7s).
Done training stage 0 (time=1115s).
---------------------------------------------------------------------------
Training stage 1
Sampled 25000 windows from 1216 images.
Done sampling windows (time=71s).
Extracting features... done (time=8s).
Training AdaBoost: nWeak=256 nFtrs=5120 pos=42526 neg=50000
 i=  16 alpha=1.000 err=0.379 loss=3.29e-01
 i=  32 alpha=1.000 err=0.374 loss=1.87e-01
 i=  48 alpha=1.000 err=0.386 loss=1.06e-01
 i=  64 alpha=1.000 err=0.382 loss=6.32e-02
 i=  80 alpha=1.000 err=0.395 loss=3.75e-02
 i=  96 alpha=1.000 err=0.380 loss=2.21e-02
 i= 112 alpha=1.000 err=0.384 loss=1.27e-02
 i= 128 alpha=1.000 err=0.383 loss=7.45e-03
 i= 144 alpha=1.000 err=0.373 loss=4.30e-03
 i= 160 alpha=1.000 err=0.378 loss=2.46e-03
 i= 176 alpha=1.000 err=0.373 loss=1.41e-03
 i= 192 alpha=1.000 err=0.378 loss=8.16e-04
 i= 208 alpha=1.000 err=0.385 loss=4.78e-04
 i= 224 alpha=1.000 err=0.391 loss=2.78e-04
 i= 240 alpha=1.000 err=0.387 loss=1.58e-04
 i= 256 alpha=1.000 err=0.376 loss=9.07e-05
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=47.2s).
Done training stage 1 (time=127s).
---------------------------------------------------------------------------
Training stage 2
Sampled 25000 windows from 2112 images.
Done sampling windows (time=97s).
Extracting features... done (time=7s).
Training AdaBoost: nWeak=1024 nFtrs=5120 pos=42526 neg=50000
 i=  16 alpha=1.000 err=0.388 loss=4.42e-01
 i=  32 alpha=1.000 err=0.411 loss=2.93e-01
 i=  48 alpha=1.000 err=0.389 loss=1.96e-01
 i=  64 alpha=1.000 err=0.395 loss=1.33e-01
 i=  80 alpha=1.000 err=0.392 loss=8.96e-02
 i=  96 alpha=1.000 err=0.394 loss=6.07e-02
 i= 112 alpha=1.000 err=0.397 loss=4.09e-02
 i= 128 alpha=1.000 err=0.398 loss=2.77e-02
 i= 144 alpha=1.000 err=0.400 loss=1.84e-02
 i= 160 alpha=1.000 err=0.394 loss=1.23e-02
 i= 176 alpha=1.000 err=0.403 loss=8.33e-03
 i= 192 alpha=1.000 err=0.404 loss=5.61e-03
 i= 208 alpha=1.000 err=0.392 loss=3.66e-03
 i= 224 alpha=1.000 err=0.408 loss=2.48e-03
 i= 240 alpha=1.000 err=0.385 loss=1.65e-03
 i= 256 alpha=1.000 err=0.400 loss=1.10e-03
 i= 272 alpha=1.000 err=0.408 loss=7.37e-04
 i= 288 alpha=1.000 err=0.400 loss=4.94e-04
 i= 304 alpha=1.000 err=0.397 loss=3.24e-04
 i= 320 alpha=1.000 err=0.399 loss=2.13e-04
 i= 336 alpha=1.000 err=0.400 loss=1.42e-04
 i= 352 alpha=1.000 err=0.401 loss=9.39e-05
 i= 368 alpha=1.000 err=0.402 loss=6.18e-05
 i= 384 alpha=1.000 err=0.397 loss=4.06e-05
 i= 400 alpha=1.000 err=0.392 loss=2.68e-05
 i= 416 alpha=1.000 err=0.399 loss=1.80e-05
 i= 432 alpha=1.000 err=0.391 loss=1.17e-05
 i= 448 alpha=1.000 err=0.389 loss=7.65e-06
 i= 464 alpha=1.000 err=0.396 loss=5.02e-06
 i= 480 alpha=1.000 err=0.403 loss=3.33e-06
 i= 496 alpha=1.000 err=0.386 loss=2.20e-06
 i= 512 alpha=1.000 err=0.397 loss=1.45e-06
 i= 528 alpha=1.000 err=0.408 loss=9.68e-07
 i= 544 alpha=1.000 err=0.396 loss=6.37e-07
 i= 560 alpha=1.000 err=0.400 loss=4.22e-07
 i= 576 alpha=1.000 err=0.400 loss=2.75e-07
 i= 592 alpha=1.000 err=0.396 loss=1.82e-07
 i= 608 alpha=1.000 err=0.390 loss=1.19e-07
 i= 624 alpha=1.000 err=0.407 loss=7.87e-08
 i= 640 alpha=1.000 err=0.393 loss=5.16e-08
 i= 656 alpha=1.000 err=0.390 loss=3.36e-08
 i= 672 alpha=1.000 err=0.396 loss=2.22e-08
 i= 688 alpha=1.000 err=0.397 loss=1.48e-08
 i= 704 alpha=1.000 err=0.396 loss=9.66e-09
 i= 720 alpha=1.000 err=0.393 loss=6.29e-09
 i= 736 alpha=1.000 err=0.393 loss=4.19e-09
 i= 752 alpha=1.000 err=0.405 loss=2.78e-09
 i= 768 alpha=1.000 err=0.402 loss=1.86e-09
 i= 784 alpha=1.000 err=0.395 loss=1.21e-09
 i= 800 alpha=1.000 err=0.400 loss=7.89e-10
 i= 816 alpha=1.000 err=0.404 loss=5.14e-10
 i= 832 alpha=1.000 err=0.400 loss=3.37e-10
 i= 848 alpha=1.000 err=0.392 loss=2.20e-10
 i= 864 alpha=1.000 err=0.403 loss=1.45e-10
 i= 880 alpha=1.000 err=0.393 loss=9.54e-11
 i= 896 alpha=1.000 err=0.402 loss=6.28e-11
 i= 912 alpha=1.000 err=0.390 loss=4.18e-11
 i= 928 alpha=1.000 err=0.395 loss=2.73e-11
 i= 944 alpha=1.000 err=0.389 loss=1.78e-11
 i= 960 alpha=1.000 err=0.388 loss=1.17e-11
 i= 976 alpha=1.000 err=0.403 loss=7.69e-12
 i= 992 alpha=1.000 err=0.399 loss=4.97e-12
 i=1008 alpha=1.000 err=0.404 loss=3.27e-12
 i=1024 alpha=1.000 err=0.396 loss=2.14e-12
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=188.4s).
Done training stage 2 (time=293s).
---------------------------------------------------------------------------
Training stage 3
Sampled 25000 windows from 15104 images.
Done sampling windows (time=578s).
Extracting features... done (time=7s).
Training AdaBoost: nWeak=4096 nFtrs=5120 pos=42526 neg=50000
 i=  16 alpha=1.000 err=0.411 loss=5.74e-01
 i=  32 alpha=1.000 err=0.411 loss=4.29e-01
 i=  48 alpha=1.000 err=0.417 loss=3.26e-01
 i=  64 alpha=1.000 err=0.418 loss=2.47e-01
 i=  80 alpha=1.000 err=0.419 loss=1.87e-01
 i=  96 alpha=1.000 err=0.419 loss=1.42e-01
 i= 112 alpha=1.000 err=0.418 loss=1.07e-01
 i= 128 alpha=1.000 err=0.417 loss=8.06e-02
 i= 144 alpha=1.000 err=0.415 loss=6.07e-02
 i= 160 alpha=1.000 err=0.422 loss=4.63e-02
 i= 176 alpha=1.000 err=0.417 loss=3.49e-02
 i= 192 alpha=1.000 err=0.420 loss=2.60e-02
 i= 208 alpha=1.000 err=0.407 loss=1.94e-02
 i= 224 alpha=1.000 err=0.410 loss=1.46e-02
 i= 240 alpha=1.000 err=0.409 loss=1.09e-02
 i= 256 alpha=1.000 err=0.413 loss=8.11e-03
 i= 272 alpha=1.000 err=0.421 loss=6.03e-03
 i= 288 alpha=1.000 err=0.420 loss=4.50e-03
 i= 304 alpha=1.000 err=0.417 loss=3.36e-03
 i= 320 alpha=1.000 err=0.414 loss=2.49e-03
 i= 336 alpha=1.000 err=0.415 loss=1.84e-03
 i= 352 alpha=1.000 err=0.411 loss=1.36e-03
 i= 368 alpha=1.000 err=0.419 loss=1.03e-03
 i= 384 alpha=1.000 err=0.407 loss=7.65e-04
 i= 400 alpha=1.000 err=0.423 loss=5.74e-04
 i= 416 alpha=1.000 err=0.410 loss=4.25e-04
 i= 432 alpha=1.000 err=0.401 loss=3.15e-04
 i= 448 alpha=1.000 err=0.416 loss=2.34e-04
 i= 464 alpha=1.000 err=0.428 loss=1.74e-04
 i= 480 alpha=1.000 err=0.414 loss=1.29e-04
 i= 496 alpha=1.000 err=0.406 loss=9.60e-05
 i= 512 alpha=1.000 err=0.409 loss=7.10e-05
 i= 528 alpha=1.000 err=0.414 loss=5.27e-05
 i= 544 alpha=1.000 err=0.419 loss=3.88e-05
 i= 560 alpha=1.000 err=0.405 loss=2.87e-05
 i= 576 alpha=1.000 err=0.409 loss=2.11e-05
 i= 592 alpha=1.000 err=0.413 loss=1.55e-05
 i= 608 alpha=1.000 err=0.422 loss=1.16e-05
 i= 624 alpha=1.000 err=0.411 loss=8.55e-06
 i= 640 alpha=1.000 err=0.416 loss=6.32e-06
 i= 656 alpha=1.000 err=0.413 loss=4.61e-06
 i= 672 alpha=1.000 err=0.418 loss=3.42e-06
 i= 688 alpha=1.000 err=0.418 loss=2.52e-06
 i= 704 alpha=1.000 err=0.412 loss=1.89e-06
 i= 720 alpha=1.000 err=0.411 loss=1.40e-06
 i= 736 alpha=1.000 err=0.416 loss=1.04e-06
 i= 752 alpha=1.000 err=0.407 loss=7.72e-07
 i= 768 alpha=1.000 err=0.411 loss=5.69e-07
 i= 784 alpha=1.000 err=0.413 loss=4.19e-07
 i= 800 alpha=1.000 err=0.421 loss=3.11e-07
 i= 816 alpha=1.000 err=0.417 loss=2.30e-07
 i= 832 alpha=1.000 err=0.413 loss=1.70e-07
 i= 848 alpha=1.000 err=0.411 loss=1.25e-07
 i= 864 alpha=1.000 err=0.410 loss=9.26e-08
 i= 880 alpha=1.000 err=0.405 loss=6.86e-08
 i= 896 alpha=1.000 err=0.420 loss=5.06e-08
 i= 912 alpha=1.000 err=0.419 loss=3.75e-08
 i= 928 alpha=1.000 err=0.418 loss=2.76e-08
 i= 944 alpha=1.000 err=0.426 loss=2.04e-08
 i= 960 alpha=1.000 err=0.409 loss=1.51e-08
 i= 976 alpha=1.000 err=0.414 loss=1.10e-08
 i= 992 alpha=1.000 err=0.418 loss=8.06e-09
 i=1008 alpha=1.000 err=0.412 loss=5.86e-09
 i=1024 alpha=1.000 err=0.418 loss=4.31e-09
 i=1040 alpha=1.000 err=0.404 loss=3.15e-09
 i=1056 alpha=1.000 err=0.406 loss=2.31e-09
 i=1072 alpha=1.000 err=0.414 loss=1.70e-09
 i=1088 alpha=1.000 err=0.413 loss=1.24e-09
 i=1104 alpha=1.000 err=0.413 loss=9.23e-10
 i=1120 alpha=1.000 err=0.414 loss=6.77e-10
 i=1136 alpha=1.000 err=0.415 loss=5.05e-10
 i=1152 alpha=1.000 err=0.413 loss=3.68e-10
 i=1168 alpha=1.000 err=0.407 loss=2.69e-10
 i=1184 alpha=1.000 err=0.406 loss=1.99e-10
 i=1200 alpha=1.000 err=0.419 loss=1.47e-10
 i=1216 alpha=1.000 err=0.411 loss=1.08e-10
 i=1232 alpha=1.000 err=0.414 loss=7.91e-11
 i=1248 alpha=1.000 err=0.413 loss=5.77e-11
 i=1264 alpha=1.000 err=0.408 loss=4.26e-11
 i=1280 alpha=1.000 err=0.417 loss=3.19e-11
 i=1296 alpha=1.000 err=0.410 loss=2.35e-11
 i=1312 alpha=1.000 err=0.420 loss=1.74e-11
 i=1328 alpha=1.000 err=0.405 loss=1.29e-11
 i=1344 alpha=1.000 err=0.411 loss=9.59e-12
 i=1360 alpha=1.000 err=0.410 loss=7.01e-12
 i=1376 alpha=1.000 err=0.412 loss=5.15e-12
 i=1392 alpha=1.000 err=0.410 loss=3.81e-12
 i=1408 alpha=1.000 err=0.429 loss=2.83e-12
 i=1424 alpha=1.000 err=0.407 loss=2.07e-12
 i=1440 alpha=1.000 err=0.415 loss=1.53e-12
 i=1456 alpha=1.000 err=0.419 loss=1.14e-12
 i=1472 alpha=1.000 err=0.419 loss=8.33e-13
 i=1488 alpha=1.000 err=0.420 loss=6.18e-13
 i=1504 alpha=1.000 err=0.414 loss=4.53e-13
 i=1520 alpha=1.000 err=0.413 loss=3.39e-13
 i=1536 alpha=1.000 err=0.409 loss=2.51e-13
 i=1552 alpha=1.000 err=0.413 loss=1.87e-13
 i=1568 alpha=1.000 err=0.414 loss=1.37e-13
 i=1584 alpha=1.000 err=0.421 loss=1.01e-13
 i=1600 alpha=1.000 err=0.422 loss=7.55e-14
 i=1616 alpha=1.000 err=0.413 loss=5.56e-14
 i=1632 alpha=1.000 err=0.400 loss=4.10e-14
 i=1648 alpha=1.000 err=0.415 loss=3.05e-14
 i=1664 alpha=1.000 err=0.426 loss=2.27e-14
 i=1680 alpha=1.000 err=0.422 loss=1.68e-14
 i=1696 alpha=1.000 err=0.410 loss=1.23e-14
 i=1712 alpha=1.000 err=0.415 loss=9.10e-15
 i=1728 alpha=1.000 err=0.407 loss=6.75e-15
 i=1744 alpha=1.000 err=0.414 loss=4.98e-15
 i=1760 alpha=1.000 err=0.406 loss=3.70e-15
 i=1776 alpha=1.000 err=0.418 loss=2.77e-15
 i=1792 alpha=1.000 err=0.412 loss=2.03e-15
 i=1808 alpha=1.000 err=0.410 loss=1.49e-15
 i=1824 alpha=1.000 err=0.416 loss=1.09e-15
 i=1840 alpha=1.000 err=0.420 loss=8.18e-16
 i=1856 alpha=1.000 err=0.407 loss=5.98e-16
 i=1872 alpha=1.000 err=0.420 loss=4.43e-16
 i=1888 alpha=1.000 err=0.411 loss=3.27e-16
 i=1904 alpha=1.000 err=0.422 loss=2.42e-16
 i=1920 alpha=1.000 err=0.410 loss=1.80e-16
 i=1936 alpha=1.000 err=0.418 loss=1.34e-16
 i=1952 alpha=1.000 err=0.415 loss=9.89e-17
 i=1968 alpha=1.000 err=0.417 loss=7.33e-17
 i=1984 alpha=1.000 err=0.416 loss=5.34e-17
 i=2000 alpha=1.000 err=0.417 loss=3.88e-17
 i=2016 alpha=1.000 err=0.418 loss=2.87e-17
 i=2032 alpha=1.000 err=0.417 loss=2.14e-17
 i=2048 alpha=1.000 err=0.412 loss=1.59e-17
 i=2064 alpha=1.000 err=0.418 loss=1.17e-17
 i=2080 alpha=1.000 err=0.418 loss=8.70e-18
 i=2096 alpha=1.000 err=0.417 loss=6.43e-18
 i=2112 alpha=1.000 err=0.413 loss=4.67e-18
 i=2128 alpha=1.000 err=0.413 loss=3.46e-18
 i=2144 alpha=1.000 err=0.418 loss=2.55e-18
 i=2160 alpha=1.000 err=0.409 loss=1.88e-18
 i=2176 alpha=1.000 err=0.408 loss=1.38e-18
 i=2192 alpha=1.000 err=0.418 loss=1.02e-18
 i=2208 alpha=1.000 err=0.413 loss=7.50e-19
 i=2224 alpha=1.000 err=0.417 loss=5.56e-19
 i=2240 alpha=1.000 err=0.413 loss=4.08e-19
 i=2256 alpha=1.000 err=0.408 loss=2.99e-19
 i=2272 alpha=1.000 err=0.407 loss=2.18e-19
 i=2288 alpha=1.000 err=0.415 loss=1.61e-19
 i=2304 alpha=1.000 err=0.408 loss=1.19e-19
 i=2320 alpha=1.000 err=0.417 loss=8.88e-20
 i=2336 alpha=1.000 err=0.416 loss=6.60e-20
 i=2352 alpha=1.000 err=0.415 loss=4.86e-20
 i=2368 alpha=1.000 err=0.416 loss=3.51e-20
 i=2384 alpha=1.000 err=0.416 loss=2.59e-20
 i=2400 alpha=1.000 err=0.405 loss=1.87e-20
 i=2416 alpha=1.000 err=0.414 loss=1.38e-20
 i=2432 alpha=1.000 err=0.404 loss=1.03e-20
 i=2448 alpha=1.000 err=0.405 loss=7.62e-21
 i=2464 alpha=1.000 err=0.412 loss=5.66e-21
 i=2480 alpha=1.000 err=0.411 loss=4.17e-21
 i=2496 alpha=1.000 err=0.417 loss=3.09e-21
 i=2512 alpha=1.000 err=0.410 loss=2.28e-21
 i=2528 alpha=1.000 err=0.408 loss=1.68e-21
 i=2544 alpha=1.000 err=0.419 loss=1.23e-21
 i=2560 alpha=1.000 err=0.416 loss=9.08e-22
 i=2576 alpha=1.000 err=0.417 loss=6.68e-22
 i=2592 alpha=1.000 err=0.415 loss=4.95e-22
 i=2608 alpha=1.000 err=0.412 loss=3.68e-22
 i=2624 alpha=1.000 err=0.413 loss=2.72e-22
 i=2640 alpha=1.000 err=0.418 loss=2.01e-22
 i=2656 alpha=1.000 err=0.414 loss=1.49e-22
 i=2672 alpha=1.000 err=0.410 loss=1.09e-22
 i=2688 alpha=1.000 err=0.419 loss=8.08e-23
 i=2704 alpha=1.000 err=0.411 loss=5.87e-23
 i=2720 alpha=1.000 err=0.415 loss=4.39e-23
 i=2736 alpha=1.000 err=0.422 loss=3.26e-23
 i=2752 alpha=1.000 err=0.415 loss=2.42e-23
 i=2768 alpha=1.000 err=0.408 loss=1.80e-23
 i=2784 alpha=1.000 err=0.408 loss=1.31e-23
 i=2800 alpha=1.000 err=0.412 loss=9.75e-24
 i=2816 alpha=1.000 err=0.421 loss=7.23e-24
 i=2832 alpha=1.000 err=0.411 loss=5.36e-24
 i=2848 alpha=1.000 err=0.421 loss=3.99e-24
 i=2864 alpha=1.000 err=0.418 loss=2.91e-24
 i=2880 alpha=1.000 err=0.417 loss=2.18e-24
 i=2896 alpha=1.000 err=0.405 loss=1.62e-24
 i=2912 alpha=1.000 err=0.406 loss=1.18e-24
 i=2928 alpha=1.000 err=0.425 loss=8.70e-25
 i=2944 alpha=1.000 err=0.409 loss=6.42e-25
 i=2960 alpha=1.000 err=0.416 loss=4.76e-25
 i=2976 alpha=1.000 err=0.419 loss=3.56e-25
 i=2992 alpha=1.000 err=0.415 loss=2.59e-25
 i=3008 alpha=1.000 err=0.406 loss=1.91e-25
 i=3024 alpha=1.000 err=0.399 loss=1.40e-25
 i=3040 alpha=1.000 err=0.417 loss=1.03e-25
 i=3056 alpha=1.000 err=0.409 loss=7.67e-26
 i=3072 alpha=1.000 err=0.410 loss=5.70e-26
 i=3088 alpha=1.000 err=0.415 loss=4.19e-26
 i=3104 alpha=1.000 err=0.406 loss=3.06e-26
 i=3120 alpha=1.000 err=0.407 loss=2.25e-26
 i=3136 alpha=1.000 err=0.410 loss=1.66e-26
 i=3152 alpha=1.000 err=0.412 loss=1.21e-26
 i=3168 alpha=1.000 err=0.416 loss=8.94e-27
 i=3184 alpha=1.000 err=0.411 loss=6.57e-27
 i=3200 alpha=1.000 err=0.407 loss=4.74e-27
 i=3216 alpha=1.000 err=0.417 loss=3.53e-27
 i=3232 alpha=1.000 err=0.412 loss=2.64e-27
 i=3248 alpha=1.000 err=0.412 loss=1.97e-27
 i=3264 alpha=1.000 err=0.405 loss=1.43e-27
 i=3280 alpha=1.000 err=0.413 loss=1.05e-27
 i=3296 alpha=1.000 err=0.421 loss=7.77e-28
 i=3312 alpha=1.000 err=0.420 loss=5.65e-28
 i=3328 alpha=1.000 err=0.408 loss=4.14e-28
 i=3344 alpha=1.000 err=0.423 loss=3.08e-28
 i=3360 alpha=1.000 err=0.410 loss=2.25e-28
 i=3376 alpha=1.000 err=0.407 loss=1.66e-28
 i=3392 alpha=1.000 err=0.407 loss=1.22e-28
 i=3408 alpha=1.000 err=0.407 loss=8.96e-29
 i=3424 alpha=1.000 err=0.419 loss=6.63e-29
 i=3440 alpha=1.000 err=0.414 loss=4.88e-29
 i=3456 alpha=1.000 err=0.410 loss=3.60e-29
 i=3472 alpha=1.000 err=0.418 loss=2.67e-29
 i=3488 alpha=1.000 err=0.414 loss=1.97e-29
 i=3504 alpha=1.000 err=0.411 loss=1.45e-29
 i=3520 alpha=1.000 err=0.405 loss=1.07e-29
 i=3536 alpha=1.000 err=0.413 loss=7.79e-30
 i=3552 alpha=1.000 err=0.414 loss=5.76e-30
 i=3568 alpha=1.000 err=0.408 loss=4.22e-30
 i=3584 alpha=1.000 err=0.415 loss=3.12e-30
 i=3600 alpha=1.000 err=0.410 loss=2.34e-30
 i=3616 alpha=1.000 err=0.422 loss=1.73e-30
 i=3632 alpha=1.000 err=0.411 loss=1.28e-30
 i=3648 alpha=1.000 err=0.414 loss=9.45e-31
 i=3664 alpha=1.000 err=0.413 loss=6.92e-31
 i=3680 alpha=1.000 err=0.416 loss=5.09e-31
 i=3696 alpha=1.000 err=0.411 loss=3.71e-31
 i=3712 alpha=1.000 err=0.407 loss=2.71e-31
 i=3728 alpha=1.000 err=0.413 loss=1.99e-31
 i=3744 alpha=1.000 err=0.413 loss=1.47e-31
 i=3760 alpha=1.000 err=0.414 loss=1.10e-31
 i=3776 alpha=1.000 err=0.413 loss=8.12e-32
 i=3792 alpha=1.000 err=0.417 loss=5.95e-32
 i=3808 alpha=1.000 err=0.411 loss=4.40e-32
 i=3824 alpha=1.000 err=0.415 loss=3.25e-32
 i=3840 alpha=1.000 err=0.419 loss=2.42e-32
 i=3856 alpha=1.000 err=0.423 loss=1.79e-32
 i=3872 alpha=1.000 err=0.413 loss=1.33e-32
 i=3888 alpha=1.000 err=0.415 loss=9.82e-33
 i=3904 alpha=1.000 err=0.408 loss=7.31e-33
 i=3920 alpha=1.000 err=0.416 loss=5.42e-33
 i=3936 alpha=1.000 err=0.406 loss=3.99e-33
 i=3952 alpha=1.000 err=0.413 loss=2.92e-33
 i=3968 alpha=1.000 err=0.414 loss=2.14e-33
 i=3984 alpha=1.000 err=0.417 loss=1.57e-33
 i=4000 alpha=1.000 err=0.414 loss=1.16e-33
 i=4016 alpha=1.000 err=0.415 loss=8.53e-34
 i=4032 alpha=1.000 err=0.427 loss=6.22e-34
 i=4048 alpha=1.000 err=0.406 loss=4.52e-34
 i=4064 alpha=1.000 err=0.420 loss=3.33e-34
 i=4080 alpha=1.000 err=0.405 loss=2.44e-34
 i=4096 alpha=1.000 err=0.415 loss=1.80e-34
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=673.7s).
Done training stage 3 (time=1260s).
---------------------------------------------------------------------------
Done training (time=2795s).
